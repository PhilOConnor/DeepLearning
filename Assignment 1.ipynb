{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac401726",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "Philip O' Connor <br>\n",
    "21249304"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f95159",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Logistic regression is a variation on multivariable linear regression where the output is reduced to a 1 or 0 using a sigmoid function.  [1]\n",
    "Input values are multiplied by a weight term and the output is discretised using a logistic funciton, like sigmoid or tanh. Stochastic gradient descent uses one observaton at a time to update the weights of w and b until either the cost function J is below a predefined threshold or it has reached the max number of iterations.\n",
    "\n",
    "[Fundamentals of Machine Learning for Predictive Data Analytics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4c0be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9ca272",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sgd_log_reg():\n",
    "        \n",
    "    def fit(self, X, y, alpha, n_iter, tresh, seed):\n",
    "        # Set seed for the random numers\n",
    "        np.random.seed(seed)\n",
    "        # Initialise w with random numbers, one for each column in training dataset\n",
    "        self.w = np.array(np.random.rand(len(X.columns)))\n",
    "        self.b = np.random.rand()\n",
    "        # Store cost in a list, first value is very high. Will use -1 indexing to check against threshold value\n",
    "        cost_list = [1000]\n",
    "        for n in range(n_iter+1):\n",
    "            # SGD - iterate through each observation, one at a time\n",
    "            for i in range(len(X)):\n",
    "                # Take a single observation\n",
    "                xi = X.iloc[i]\n",
    "                yi = y.iloc[i]\n",
    "\n",
    "                # Calculate y_hat\n",
    "                z = np.dot(self.w, xi)+self.b \n",
    "                y_hat = 1/(1+np.exp(-z))\n",
    "                # Calcualte cost funciton \n",
    "                cost = -(yi*np.log(y_hat))+((1-yi)*np.log(1-y_hat))\n",
    "\n",
    "                # While previous cost is higher than threshold\n",
    "                if cost_list[-1]-cost > tresh:\n",
    "                    cost_list.append(cost)\n",
    "                    # Calculate gradients of w and b\n",
    "                    for weight in self.w:\n",
    "                        del_w = (y_hat-yi)*xi\n",
    "                        del_b = y_hat-yi\n",
    "                    # Update w and b\n",
    "                    for weight in self.w:\n",
    "                        self.w = self.w - alpha*del_w\n",
    "                        self.b = self.b - alpha*del_b\n",
    "\n",
    "                # If cost is below the threshold then break out of the loop\n",
    "                elif  cost_list[-1]-cost <= tresh:\n",
    "                    break\n",
    "        # If the funciton runs for all n iterations then it has not converged. Print out the warning so user can update hyperparameters.\n",
    "        if n == n_iter:\n",
    "            print(f\"{n} of {n_iter} iterations ran. Convergence has not happened. Cost is {cost}\")\n",
    "        if n < n_iter:\n",
    "            print(f\"{n} of {n_iter} iterations ran. Convergence has happened. Cost is {cost}\")\n",
    "            \n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.w)+self.b\n",
    "        y_hat_test = 1/(1+np.exp(-z))\n",
    "\n",
    "        # Discretise the output into 1s and 0s\n",
    "        y_hat_rounded = np.round(y_hat_test,0)\n",
    "        y_hat_int = [int(i) for i in y_hat_rounded]\n",
    "        return y_hat_int\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e401916",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5231c157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 of 10000 iterations ran. Convergence has not happened. Cost is 0.4384361128147499\n",
      "F1 score: 0.5\n",
      "Precision:0.67\n",
      "Recall: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Blobs\n",
    "df = pd.read_csv(\"blobs400.csv\")\n",
    "# train/test split~\n",
    "X_full_train, X_test, y_full_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.15, random_state=42)\n",
    "# train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_full_train,y_full_train , test_size=0.15, random_state=42)\n",
    "\n",
    "# train on training dataset\n",
    "blobs_model = sgd_log_reg()\n",
    "blobs_model.fit(X_train, y_train, alpha=0.1, n_iter=10000, tresh=10**-6, seed=42)\n",
    "\n",
    "val_preds = blobs_model.predict(X_val)\n",
    "\n",
    "# Calculate some performace metrics\n",
    "f1 = f1_score(y_val, val_preds)\n",
    "prec = precision_score(y_val, val_preds)\n",
    "rec = recall_score(y_val, val_preds)\n",
    "\n",
    "print(f\"F1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0993a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.38\n",
      "Precision:0.47\n",
      "Recall: 0.32\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions from the model. \n",
    "test_preds = blobs_model.predict(X_test)\n",
    "\n",
    "# Calculate some performace metrics\n",
    "f1 = f1_score(y_test, test_preds)\n",
    "prec = precision_score(y_test, test_preds)\n",
    "rec = recall_score(y_test, test_preds)\n",
    "\n",
    "print(f\"F1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69acdbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=3, sharey=True, figsize=(9,9))\n",
    "sns.scatterplot(x=X_test['X1'], y=X_test['X1'], ax=axs[0,0], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X2'], y=X_test['X1'], ax=axs[0,1], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X3'], y=X_test['X1'], ax=axs[0,2], hue =y_test,  style=test_preds)\n",
    "\n",
    "sns.scatterplot(x=X_test['X1'], y=X_test['X2'], ax=axs[1,0], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X2'], y=X_test['X2'], ax=axs[1,1], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X3'], y=X_test['X2'], ax=axs[1,2], hue =y_test,  style=test_preds)\n",
    "\n",
    "sns.scatterplot(x=X_test['X1'], y=X_test['X3'], ax=axs[2,0], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X2'], y=X_test['X3'], ax=axs[2,1], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X3'], y=X_test['X3'], ax=axs[2,2], hue =y_test,  style=test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ef2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"moons500.csv\")\n",
    "\n",
    "# train/test split\n",
    "X_full_train, X_test, y_full_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.3, random_state=42)\n",
    "# train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_full_train,y_full_train , test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model to data\n",
    "moons_model = sgd_log_reg()\n",
    "moons_model.fit(X_train, y_train, alpha=0.1, n_iter=1000, tresh=10**-6, seed=1)\n",
    "# calculate predictions from the model. Skipping validation as the assignment is coding a logistic regression.\n",
    "\n",
    "val_preds = moons_model.predict(X_val)\n",
    "\n",
    "# Calculate some performace metrics\n",
    "f1 = f1_score(y_val, val_preds)\n",
    "prec = precision_score(y_val, val_preds)\n",
    "rec = recall_score(y_val, val_preds)\n",
    "\n",
    "print(f\"F1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdfd5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = moons_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate some performace metrics\n",
    "f1 = f1_score(y_test, test_preds)\n",
    "prec = precision_score(y_test, test_preds)\n",
    "rec = recall_score(y_test, test_preds)\n",
    "\n",
    "print(f\"F1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(data = X_test, x='X1', y='X2', hue =y_test,  style=test_preds, legend='brief')\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba35a97",
   "metadata": {},
   "source": [
    "# Part 3 - Shallow neutal network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_fn(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def logistic_derivation(z):\n",
    "    return logistic_fn(z)*(1-logistic_fn(z))\n",
    "\n",
    "class shallow_net():\n",
    "    \n",
    "    def network_layout(self, n_input, n_nodes, n_output, seed):\n",
    "        # Build and initialise the network weights and biases with random values between 0 and 1 \n",
    "        np.random.seed(seed)\n",
    "        self.n_nodes = n_nodes\n",
    "        self.hidden_layer_weights = np.random.rand(n_nodes,n_input)-0.5\n",
    "        self.hidden_layer_bias = np.random.rand(n_nodes)\n",
    "        self.output_layer_weights = np.random.rand(n_nodes)\n",
    "        self.output_layer_bias = np.random.rand()\n",
    "    \n",
    "    def print_network(self):\n",
    "        # Print out the current weights and biases of the network\n",
    "        print(\"Hidden Weights:\\n\")\n",
    "        print(self.hidden_layer_weights)\n",
    "        print(\"\\nHidden Bias:\\n\")\n",
    "        print(self.hidden_layer_bias)\n",
    "        print(\"Output Weights:\\n\")\n",
    "        print(self.output_layer_weights)\n",
    "        print(\"\\nOutput Bias:\\n\")\n",
    "        print(self.output_layer_bias)\n",
    "    \n",
    "    def return_network(self):\n",
    "        # Return values of the network\n",
    "        return self.hidden_layer_weights, self.hidden_layer_bias, self.output_layer_weights, self.output_layer_bias\n",
    "\n",
    " \n",
    "\n",
    "    def fit(self, X, y, alpha, n_iter, thresh):\n",
    "        # For each iteration\n",
    "        \n",
    "        j2=100\n",
    "        for n in range(n_iter+1):\n",
    "            # Check if threshold is met\n",
    "            if j2 <= thresh:\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # Print a progress update\n",
    "            if n%(n_iter/5)==0:\n",
    "                print(f\"{n}/{n_iter} complete\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            # SGD - iterate through each observation, one at a time\n",
    "            for i in range(len(X_train)):\n",
    "                # Take a single observation\n",
    "                xi = X_train.iloc[i]\n",
    "                yi = y_train.iloc[i]\n",
    "                # Create some lists to store values in.\n",
    "                hidden_layer_cost=[]\n",
    "                a1=np.array([])\n",
    "                j1 = []\n",
    "                z1_list=[]\n",
    "                del_z_hidden_list=[]\n",
    "\n",
    "\n",
    "                # For each node in hidden layer calculate z, activation and the cost                \n",
    "                \n",
    "                # Calculate y_hat\n",
    "                z1 = np.dot(self.hidden_layer_weights, xi.T)+self.hidden_layer_bias \n",
    "                a1 = logistic_fn(z1)\n",
    "\n",
    "                # Calcualte cost funciton - not used but no harm in tracking\n",
    "                hidden_layer_cost.append(-(yi*np.log(a1))+((1-yi)*np.log(1-a1)))\n",
    "                    \n",
    "                # In the output layer calculate z, activation and the cost\n",
    "                z2 = np.dot(a1,self.output_layer_weights) +self.output_layer_bias\n",
    "                a2 = logistic_fn(z2)\n",
    "                # Calcualte cost funciton \n",
    "                j2 = -(yi*np.log(a2))+((1-yi)*np.log(1-a2))\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "                # Back propogation\n",
    "                # Output node\n",
    "                del_z_output = a2-yi \n",
    "                del_w_output = np.dot(del_z_output,a1.T)\n",
    "                del_b_output = del_z_output\n",
    "                \n",
    "\n",
    "                # Hidden Layer\n",
    "                # For each node in the hidden layer, calc the del_z wrt its output node weight and store in a list\n",
    "\n",
    "                del_z_hidden = logistic_derivation(z1)*np.dot(self.output_layer_weights,del_z_output)\n",
    "                #del_z_hidden_list.append(del_z_hidden)\n",
    "                # Reshape the vectors to return a matrix that can be used to update the hidden weights.\n",
    "                del_w_hidden = np.array(del_z_hidden.reshape((self.n_nodes,1)))*np.array(xi)\n",
    "                del_b_hidden = del_z_hidden\n",
    "                #pdb.set_trace()\n",
    "                \n",
    "                \"\"\"\n",
    "                del_z_hidden = logistic_derivation(z1)*np.dot(self.output_layer_weights.T,del_z_output)\n",
    "                #del_z_hidden_list.append(del_z_hidden)\n",
    "                # Reshape the vectors to return a 2x2 matrix that can be used to update the hidden weights.\n",
    "                del_w_hidden = np.array(del_z_hidden.reshape((self.n_nodes,1)))*np.array(xi).T\n",
    "                del_b_hidden = del_z_hidden\"\"\"\n",
    "                \n",
    "                    \n",
    "                # Update the hidden layer weights with the matrix calculated above\n",
    "                self.hidden_layer_weights = self.hidden_layer_weights - (alpha*del_w_hidden)\n",
    "                # Update bidden layer bias\n",
    "                self.hidden_layer_bias = self.hidden_layer_bias - (alpha * del_b_hidden)\n",
    "                    \n",
    "                self.output_layer_weights = self.output_layer_weights - (alpha*del_w_output)\n",
    "                self.output_layer_bias = self.output_layer_bias - (alpha*del_b_output)\n",
    "                #pdb.set_trace()\n",
    "        \n",
    "        # Creating attributes to query them \n",
    "        self.a1 = a1\n",
    "        self.a2 = a2\n",
    "        self.del_z_output = del_z_output\n",
    "        self.del_w_output = del_w_output\n",
    "        self.del_b_output = del_b_output \n",
    "\n",
    "        # Hidden Layer\n",
    "        self.del_z_hidden = del_z_hidden\n",
    "        self.del_w_hidden = del_w_hidden\n",
    "        self.del_b_hidden = del_b_hidden\n",
    "\n",
    "\n",
    "        print(f\"{n} iterations ran\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions=[]\n",
    "        for i in range(len(X)):\n",
    "            # Take a single observation\n",
    "            xi = X.iloc[i]\n",
    "            a1_pred = []\n",
    "\n",
    "            z1 = np.dot(self.hidden_layer_weights, xi)+self.hidden_layer_bias\n",
    "            a1_pred = logistic_fn(z1)\n",
    "\n",
    "            \n",
    "            z2 = np.dot(a1_pred,self.output_layer_weights) +self.output_layer_bias\n",
    "            a2 = logistic_fn(z2)\n",
    "            predictions.append(a2)\n",
    "            #pdb.set_trace()\n",
    "        return [int(i) for i in np.round(predictions,0)]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "                \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d2132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Blobs\n",
    "df = pd.read_csv(\"blobs400.csv\")\n",
    "# train/test split~\n",
    "X_full_train, X_test, y_full_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.15, random_state=42)\n",
    "# train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_full_train,y_full_train , test_size=0.15, random_state=42)\n",
    "\n",
    "blobs_nn = shallow_net()\n",
    "\n",
    "blobs_nn.network_layout(len(X_train.columns), len(X_train.columns),1, seed=45)\n",
    "\n",
    "blobs_nn.fit(X_train, y_train, alpha=0.2, n_iter=100, thresh = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821db87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = blobs_nn.predict(X_val)\n",
    "f1 = f1_score(y_val, preds_val)\n",
    "prec = precision_score(y_val, preds_val)\n",
    "rec = recall_score(y_val, preds_val)\n",
    "print(f\"Validation:\\nF1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d31684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = blobs_nn.predict(X_test)\n",
    "f1 = f1_score(y_test, test_preds)\n",
    "prec = precision_score(y_test, test_preds)\n",
    "rec = recall_score(y_test, test_preds)\n",
    "print(f\"Testing:\\nF1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=3, sharey=True, figsize=(12,12))\n",
    "sns.scatterplot(x=X_test['X1'], y=X_test['X1'], ax=axs[0,0], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X2'], y=X_test['X1'], ax=axs[0,1], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X3'], y=X_test['X1'], ax=axs[0,2], hue =y_test,  style=test_preds)\n",
    "\n",
    "sns.scatterplot(x=X_test['X1'], y=X_test['X2'], ax=axs[1,0], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X2'], y=X_test['X2'], ax=axs[1,1], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X3'], y=X_test['X2'], ax=axs[1,2], hue =y_test,  style=test_preds)\n",
    "\n",
    "sns.scatterplot(x=X_test['X1'], y=X_test['X3'], ax=axs[2,0], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X2'], y=X_test['X3'], ax=axs[2,1], hue =y_test,  style=test_preds)\n",
    "sns.scatterplot(x=X_test['X3'], y=X_test['X3'], ax=axs[2,2], hue =y_test,  style=test_preds)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729af428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blobs\n",
    "df = pd.read_csv(\"moons500.csv\")\n",
    "# train/test split~\n",
    "X_full_train, X_test, y_full_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.15, random_state=42)\n",
    "# train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_full_train,y_full_train , test_size=0.15, random_state=42)\n",
    "\n",
    "moons_nn = shallow_net()\n",
    "\n",
    "moons_nn.network_layout(len(X_train.columns), len(X_train.columns),1, seed=80)\n",
    "\n",
    "moons_nn.fit(X_train, y_train, alpha=0.01, n_iter=100, thresh = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453291c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_preds= moons_nn.predict(X_train)\n",
    "\n",
    "preds_val = moons_nn.predict(X_val)\n",
    "f1 = f1_score(y_val, preds_val)\n",
    "prec = precision_score(y_val, preds_val)\n",
    "rec = recall_score(y_val, preds_val)\n",
    "print(f\"Validation:\\nF1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds =moons_nn.predict(X_test)\n",
    "#test_preds.columns = ['y_hat']\n",
    "f1 = f1_score(y_test, test_preds)\n",
    "prec = precision_score(y_test, test_preds)\n",
    "rec = recall_score(y_test, test_preds)\n",
    "print(f\"Testing:\\nF1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(data = X_test, x='X1', y='X2', hue =y_test,  style=test_preds, legend='brief')\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fcb1b3",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "The shallow neural net has performed much better on both datasets on F1, precision and recall. The decision boundaries in the plots are also far more appropriate. In the blobs dataset, there is clear separation of the two classes even when not linearly seperable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab418d7",
   "metadata": {},
   "source": [
    "# Part 4 - Fashion MNIST\n",
    "\n",
    "The categories assigned to me are tshirt/top and ankle boot. <br>\n",
    "The index positions of these in the lables provided are 0 and 9 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f05b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function taken directly from the Fashion-MNIST github site: \n",
    "# https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "\n",
    "# Note: first arg is the path name, second is the file prefix, either 'train' or 't10k' (which is 10k of test data)\n",
    "def load_mnist(path, kind='train'): \n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Loaded in this way, each of the batch files contains a dictionary with the following elements:\n",
    "#   data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. \n",
    "#           The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. \n",
    "#           The image is stored in row-major order, so that the first 32 entries of the array are the red channel values \n",
    "#           of the first row of the image.\n",
    "#   labels -- a list of 10000 numbers in the range 0-9. \n",
    "#             The number at index i indicates the label of the ith image in the array data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bffa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_imgs, train_labels) = load_mnist(\"fashion-mnist/data/fashion/\")\n",
    "\n",
    "label_names = ['T-shirt/top', 'Trouser' , 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "full_df =pd.DataFrame(train_imgs) \n",
    "full_df['labels'] = train_labels\n",
    "df = full_df[full_df['labels']==0]\n",
    "df = df.append(full_df[full_df['labels']==9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5de8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RE-encoding the lables for the logistic regressor\n",
    "# tshirt/top = 0\n",
    "# Ankle boot = 1\n",
    "df.loc[df.labels == 9 ,'labels']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a961a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.30, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d55308",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = len(X_train.columns)\n",
    "sample_X = X_train.sample(1000)\n",
    "indexes = sample_X.index.values\n",
    "sample_y = y_train[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_nn = shallow_net()\n",
    "\n",
    "fashion_nn.network_layout(n_inputs, 40,1, seed=20)\n",
    "\n",
    "fashion_nn.fit(X_train, y_train, alpha=0.01, n_iter=100, thresh = 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc7fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = fashion_nn.predict(X_val)\n",
    "\n",
    "f1 = f1_score(y_val, preds_val)\n",
    "prec = precision_score(y_val, preds_val)\n",
    "rec = recall_score(y_val, preds_val)\n",
    "print(f\"Validation:\\nF1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = fashion_nn.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, test_preds)\n",
    "prec = precision_score(y_test, test_preds)\n",
    "rec = recall_score(y_test, test_preds)\n",
    "print(f\"Test:\\nF1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13785232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('   y','y^')\n",
    "[i for i in zip(y_test[:10], test_preds[:10])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa71f6c9",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "\n",
    "There's something wrong with how im handling my matrices, I'm losing the output weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4a80426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_fn(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def logistic_derivation(z):\n",
    "    return logistic_fn(z)*(1-logistic_fn(z))\n",
    "\n",
    "class deep_net():\n",
    "    def __init__(self):\n",
    "        self.weights=[]\n",
    "        self.bias=[]\n",
    "        \n",
    "    \n",
    "    def network_layout(self, arch, seed):\n",
    "        # Build and initialise the network weights and biases with random values between 0 and 1 \n",
    "        np.random.seed(seed)\n",
    "        self.n_layers= len(arch)\n",
    "        for i in range(len(arch)):\n",
    "            if i>=1:\n",
    "                self.weights.append(np.random.rand(arch[i], arch[i-1])-0.5)\n",
    "                self.bias.append(np.random.rand(arch[i]))\n",
    "\n",
    "    \n",
    "    def print_network(self):\n",
    "        # Print out the current weights and biases of the network\n",
    "        for i in range(len(self.weights)):\n",
    "            print(f\"Layer {i+1} of {len(self.weights)}\")\n",
    "            print(f\"{self.weights[i]}\")\n",
    "    \n",
    "    def return_network(self):\n",
    "        # Return values of the network\n",
    "        return self.weights, self.bias\n",
    "\n",
    "    def fit(self, X, y, alpha, n_iter, thresh):\n",
    "        j2=100\n",
    "        for n in range(n_iter+1):\n",
    "            # Check if threshold is met\n",
    "            if j2 <= thresh:\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "            # Print a progress update\n",
    "            if n%(n_iter/5)==0:\n",
    "                print(f\"{n}/{n_iter} complete\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            # SGD - iterate through each observation, one at a time\n",
    "            for i in range(len(X_train)):\n",
    "                # Take a single observation\n",
    "                xi = X_train.iloc[i]\n",
    "                yi = y_train.iloc[i]\n",
    "                zx_list=[]\n",
    "                ax_list=[]\n",
    "                # Create some lists to store values in.\n",
    "\n",
    "                # For each node in hidden layer calculate z, activation and the cost                \n",
    "                #pdb.set_trace()\n",
    "                for w in range(len(self.weights)):\n",
    "                    if w==0:\n",
    "                        zx = np.dot(self.weights[w], xi.T)+self.bias[w]\n",
    "                        ax = logistic_fn(zx)\n",
    "                        zx_list.append(zx)\n",
    "                        ax_list.append(ax)\n",
    "\n",
    "                    else:\n",
    "                        zx = np.dot(self.weights[w], zx.T)+self.bias[w]\n",
    "                        ax = logistic_fn(zx)\n",
    "                        zx_list.append(zx)\n",
    "                        ax_list.append(ax)                        \n",
    "                      \n",
    "                jx = -(yi*np.log(ax))+((1-yi)*np.log(1-ax))\n",
    "                    \n",
    "\n",
    "                dw_list=[]\n",
    "                db_list=[]\n",
    "\n",
    "                # Back propogation\n",
    "                # Output node\n",
    "                #pdb.set_trace()\n",
    "                for w in range(len(self.weights)-1,-1,-1):\n",
    "                    #pdb.set_trace()\n",
    "                    if w==len(self.weights)-1:\n",
    "                        dz = ax-yi\n",
    "                        dw = dz*ax_list[w-1]\n",
    "                        db=dz\n",
    "                        dw_list.append(dw)\n",
    "                        db_list.append(dz)\n",
    "                        \n",
    "                        \n",
    "                    else:\n",
    "                        #pdb.set_trace()\n",
    "                        dz = logistic_derivation(zx_list[w])*np.sum(self.weights[w+1]*zx_list[w+1])\n",
    "                        dw = np.array(dz.reshape((len(zx_list[w]),1)))*np.array(ax_list[w-1])\n",
    "                        db = dz\n",
    "                        dw_list.append(dw)\n",
    "                        db_list.append(dz)\n",
    "                #pdb.set_trace()\n",
    "\n",
    "\n",
    "                # Pre dw_list reverse\n",
    "                #pdb.set_trace()\n",
    "                dw_list = dw_list[::-1]\n",
    "                db_list = db_list[::-1]\n",
    "                # Pst dw_list reverse\n",
    "                #pdb.set_trace()\n",
    "\n",
    "\n",
    "                # Update the hidden layer weights with the matrix calculated above\n",
    "                for w in range(len(self.weights)):\n",
    "                    self.weights[w] = self.weights[w] - np.dot(alpha,dw_list[w])\n",
    "                    self.bias[w] = self.bias[w] - np.dot(alpha,db_list[w])\n",
    "        \n",
    "        # Creating attributes to query them \n",
    "        self.ax_list = ax_list\n",
    "        self.db_list = db_list\n",
    "        self.dw_list = dw_list\n",
    "        #pdb.set_trace()\n",
    "\n",
    "        print(f\"{n} iterations ran\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions=[]\n",
    "        for n in range(len(X)):\n",
    "            xi=X.iloc[n]\n",
    "            #pdb.set_trace()\n",
    "            # Take a single observation\n",
    "            for w in range(len(self.weights)):\n",
    "                if w==0:\n",
    "                    #pdb.set_trace()\n",
    "                    zx = np.dot(self.weights[w], xi.T)+self.bias[w]\n",
    "                    ax = logistic_fn(zx)\n",
    "\n",
    "                else:\n",
    "                    zx = np.dot(self.weights[w], zx.T)+self.bias[w]\n",
    "                    ax = logistic_fn(zx)\n",
    "       \n",
    "            #pdb.set_trace()\n",
    "            predictions.append(ax)\n",
    " \n",
    "            #pdb.set_trace()\n",
    "        return [int(i) for i in np.round(predictions,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dadc31bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1000 complete\n",
      "200/1000 complete\n",
      "400/1000 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-131-455a4e48d31d>:72: RuntimeWarning: divide by zero encountered in log\n",
      "  jx = -(yi*np.log(ax))+((1-yi)*np.log(1-ax))\n",
      "<ipython-input-131-455a4e48d31d>:72: RuntimeWarning: invalid value encountered in multiply\n",
      "  jx = -(yi*np.log(ax))+((1-yi)*np.log(1-ax))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/1000 complete\n",
      "800/1000 complete\n",
      "1000/1000 complete\n",
      "1000 iterations ran\n"
     ]
    }
   ],
   "source": [
    "test = deep_net()\n",
    "\n",
    "test.network_layout([len(X_train.columns),6, 6, 1], 20)\n",
    "\n",
    "test.fit(X_train, y_train, alpha=0.02, n_iter=1000, thresh = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5d39a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "F1 score: 0.84\n",
      "Precision:0.77\n",
      "Recall: 0.92\n"
     ]
    }
   ],
   "source": [
    "preds_val = test.predict(X_val)\n",
    "f1 = f1_score(y_val, preds_val)\n",
    "prec = precision_score(y_val, preds_val)\n",
    "rec = recall_score(y_val, preds_val)\n",
    "print(f\"Validation:\\nF1 score: {np.round(f1,2)}\\nPrecision:{np.round(prec,2)}\\nRecall: {np.round(rec,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "442b44d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y y^\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 0)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('   y','y^')\n",
    "[i for i in zip(y_test, preds_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2eca5600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22991ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
